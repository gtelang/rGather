%!TEX root = r-gather.tex

\section{Decentralized algorithm}


In this section, we consider the $r$-gather as a distributed computation problem. This approach is particularly relevant in the context of locations, where data is naturally spread over a spatial region, and we can use local computations at access points and local devices for anonymization and cloaking. This approach also provides better security and privacy, since it is harder for an attacker to compromise many devices spread over a large region.

\subsection{Distributed computation and location management}

We consider the problem from an {\em edge computation} perspective, where computation is pushed away from central servers and toward the edges of the network. Computations may be carried out in mobile phones themselves, or in other local facilities, such as access points, cellular base stations or other local servers. In such setups, a mobile device may not need to perform its own computations, which may instead be performed by servers in charge of each locality. 

We assume that each mobile device is capable of finding its approximate location, either from GPS or from the presence of nearby transmitters (e.g., cell towers). We also assume that the devices report their location changes to a distributed location management system such as~\cite{abraham04LLS}. Such location management systems can be modified easily to respond to range queries, such as how many nodes are present in a given area~\cite{Sarkar:2010:forms}. In the following, we assume that every node can query the location server to find nodes within any particular distance from it, and thus derive its $r$ nearest neighbors. We follow the general distributed computation terminology of a node performing computations, but,  in general, location servers may be carrying out the computations on behalf of the nodes. We give more details of location management and neighborhood queries in Subsection~\ref{subsec:dynamic}


\subsection{Maximal independent neighborhoods}


For any point $p_i$, we let $p_i^{(r)}$ denote its $r^{th}$ nearest neighbor in $P$, and we let $d_{r}(p_{i}) = \abs{p_{i} - p_{i}^{(r)}}$ denote the corresponding distance. We let $N_{r}(p_{i})$ denote the set of $r$ nodes nearest to point $p_i$, and let $N(P)=\{N(p_{i}): p_{i}\in P\}$ denote the set of such {\em $r$-neighborhoods}. If $N_{r}(p_{i}) \cap N_{r}(p_{j})=\emptyset$, we say that the $r$-neighborhoods of $p_{i}$ and $p_{j}$ are {\em independent}.

%Our general strategy will be to create disks in the plane, with each disk containing at least $r$ nodes. Thus, centered at a point $p_{i}$, we consider disks of radius $d_{r}(p_{i})$, which we denote by $D_{r}(p_{i})$. We call two disks $D$ and $D^{\prime}$ independent if the nodes in them do not intersect, that is, $D\cap P \cap D^{\prime} = \emptyset$. 

We let $\G$ denote the set of clusters, at any stage of our algorithm; $\G$ is initialized to $\emptyset$. 
% NOT USED at the moment: We let $G(p_{i}) \in \G$ denote the cluster that contains node $p_{i}$. 
We let $c_G$ denote the {\em center} of cluster $G\in \G$; the center $c_G$ may be either a node (in $P$) or another location.

The basic algorithm executes the following steps to construct the set $\G$ of clusters:
\begin{enumerate}
\item[M1] At each point $p_{i}\in P$, compute $p_{i}^{(r)}$, $d_{r}(p_{i})$ and $N_{r}(p_{i})$.
\item[M2] Find a maximal independent subset of neighborhoods from the set $N_{r}(P)$, add each as a cluster in $\G$, and {\em mark} the nodes (as ``clustered'') in these sets.
\item[M3]  For any unmarked node $p_{i}\in P$, assign $p_{i}$ to the cluster $G\in\G$ whose center, $c_G$, is closest to $p_{i}$.
%% with the nearest center, that is $\dst\argmin_{G^{j}}{\abs{p_{i}-p_{j}}}$ and mark $i$ as clustered. 
\end{enumerate}

The nodes that belong to $r$-neighborhoods of cluster centers and added to clusters in step M2 are called {\em canonical} members of the cluster, while nodes that are added in step M3, are called the {\em outer} members. 


%In this section, we describe a 4-approximation algorithm for $r$-gather that is less centralized than the 2-approximation in \cite{Aggarwal06achievinganonymity}.  We begin with an algorithm that is not explicitly decentralized and then later detail how to do so.

%Let the $r$-neighborhood of a point $p_i$ or $N_r(p_i)$ denote the set containing $p_i$ and the closest $r-1$ points to $p_i$.  Let $N$ be the set of the $r$-neighborhoods of all points in $P$.  For each $r$-neighborhood, we define a distance $R_i^r = \max_{p_j \in N_r(p_i)}||p_i - p_j||$ and we define a distance $R^r = \max_{1 \leq i \leq n}R_i^r$ among all $r$-neighborhoods.  We first find a maximal independent set $S$ of $r$-neighborhoods.  For an $r$-neighborhood $N_r(p_i)$, we name $p_i$ the center of the cluster and all other points in $N_r(p_i)$ are named the cannonical set.  Each point $p_i$ that is not in a set in $S$ must have at least one point in it's $r$-neighborhood that is in a set in $S$ (otherwise $S$ is not maximal).  We assign $p_i$ to the set of one of these points.  Such a point is named an outer member of its set.  We claim that the resulting clustering $S'$ is a 4-approximation $r$-gather clustering.  


Next, we argue that this simple algorithm approximates an optimal clustering. Let $d_{r}^{\max} = \max_{i}{d_{r}(p_{i})}$ be the largest distance from a node to its $r^{th}$ nearest neighbor. Let $D_{OPT}$ be the diameter of the largest cluster in an optimal clustering.  We then observe

\begin{observation}
%%For any set of nodes in the plane, 
$D_{OPT}\geq d_{r}^{\max}$.
\end{observation}
\begin{proof}
Suppose $p_{i}\in P$ is a point achieving $d_{r}^{\max}$: $d_{r}(p_{i}) = d_{r}^{\max}$. Since any disk of radius less than $d_{r}^{max}$ centered at $p_{i}$ does not contain $r$ nodes, a disk that contains $p_{i}$ as well as (at least) $r-1$ other nodes must have radius at least $d_{r}^{max}/2$. Thus the diameter $D_{OPT}$ must be at least $d_{r}^{\max}$.
\end{proof}

\begin{lemma}
For any cluster $G\in \G$ and any node $p_{i}\in G$, $|p_{i} - c_G| \leq d_r(p_{i})+d_r(c_G)$.
%%  distance from $x$ to $j$ is bounded by $\abs{p_{x} - p_{j}}\leq d_{r}(p_{j}) + d_{r}(p_{x})$. 
\label{lem:local-lemma}
\end{lemma}
\begin{proof}
Consider a cluster $G\in\G$, centered at $c_G$, and $p_{i}\in G$. 

If $p_{i}$ was assigned to cluster $G$ in step M2, then we know that $p_{i}\in N_r(c_G)$, implying that $|p_{i} - c_G| \leq d_r(c_G) \leq d_r(p_{i})+ d_r(c_G)$.

% All nodes added to $G$ in step M2 of the algorithm are within a distance $d_{r}(c_G)$ of $c_G$; thus, all nodes in $G$ are within distance $2d_{r}(c_G)$ of each other. 

If $p_{i}$ was not assigned to cluster $G$ in step M2, but was instead assigned to $G$ in step M3, then we know, by maximality of the independent set, that the $r$-neighborhood $N_r(p_i)$ intersects some other $r$-neighborhood, say $N_r(p_j)$, that was a cluster in the maximal independent set in step M2.  (It may or may not be the case that $G=N_r(p_j)$.)  Since the disk of radius $d_r(p_i)$ centered at $p_i$ intersects the disk of radius $d_r(p_j)$ centered at $p_j$, and $p_i$ is closer (or at the same distance) to $c_G$ than to $p_j$, we know that the disk of radius $d_r(p_i)$ centered at $p_i$ also intersects the disk of radius $d_r(c_G)$ centered at $c_G$. Thus, there is a point $q$ in the intersection of these two disks (the disk of radius $d_r(p_i)$ centered at $p_i$ and the disk of radius $d_r(c_G)$ centered at $c_G$), implying that $|p_i - q|\leq d_r(p_i)$ and that $|q - c_G|\leq d_r(c_G)$.  The triangle inequality implies then that $|p_i-c_G|\leq |p_i-q|+|q-c_G|\leq d_r(p_i)+d_r(c_G)$.  
%Now consider a node $p_j\in P$ that is not assigned to a cluster in step M2; $p_j$ is assigned to a cluster in step M3. That $x$ is not clustered implies that one or more nodes in $N_{r}(p_{x})$ belongs to some other neighborhood $N_{r}(p_{j)}$ for a cluster $G^{j}$. Let $y\in N_{r}(p_{x})\cap N_{r}(p_{j})$ be such a node. Then by definition, $\abs{p_{x}-p_{y}}\leq d_{r}(p_{x})$ and $\abs{p_{y} - p_{j}}\leq d_{r}(p_{j})$. Thus, by triangle inequality, $\abs{p_{x} - p_{j}}\leq d_{r}(p_{j}) + d_{r}(x)$.
\end{proof}

From the above lemma it follows that the algorithm produces a $4$-approximation of the diameter:

\begin{corollary}
The diameter of any $G\in \G$ is at most $4D_{OPT}$.
\end{corollary}
\begin{proof}
Consider any $p_i,p_j\in G$.  By Lemma~\ref{lem:local-lemma}, 
$|p_i-c_G|\leq d_r(p_i)+d_r^{\max}\leq 2d_r^{\max}$ and
$|p_j-c_G|\leq d_r(p_j)+d_r^{\max}\leq 2d_r^{\max}$.
Thus, by the triangle inequality, $|p_i-p_j|\leq 2d_r^{\max} + 2d_r^{\max} = 4d_r^{\max} \leq 4D_{OPT}$. 
%Since any $d_{r}(\cdot)\leq d_{r}^{\max}$, it follows using triangle inequality that: \[ \abs{p_{x} - p_{z}}\leq \abs{p_{x}-p_{j}} + \abs{p_{y}-p_{j}}\leq  4D_{OPT}\]
\end{proof}

%\myparagraph{Randomized algorithm.} 
The maximal independent subsets in step M2 can be computed rapidly, in time $O(\log n)$, using the randomized parallel algorithm of Alon et al.~\cite{alon1986fast}, applied to compute a maximal independent set in the intersection graph of the neighborhoods $N(P)$ (i.e., in the graph whose nodes are the $r$-neighborhoods $N(p_{i})$ and whose edges link two $r$-neighborhoods that have a nonempty intersection).

%% as follows. We construct a graph $H$ on the set of nodes such that any edge $(i,j)$ exists iff $N_{r}(p_{i})\cap N_{r}(p_{j})\neq \emptyset$. The maximal independent subset of neighborhoods in step M2 is then equivalent to computation of a maximal independent set on this graph $H$. We can then use a randomized computation such as~\cite{alon1986fast} to compute the independent neighborhoods in $O(\log n)$ time.

The algorithm just described guarantees a $4$-approximation overall; however, from the point of view of a particular node this may not be satisfactory. The bound on the diameter for all clusters is dominated by the worst case -- the clusters in the sparsest neighborhood. A node in a densely populated region can justifiably expect to be assigned to a cluster center close to itself, which is not guaranteed by the algorithm above. We thus describe next another algorithm that guarantees geographic coherence of clusters, meaning that the distance of a node $p_{i}$ to its cluster center is bounded by a factor of its distance, $d_{r}(p_{i})$, to its $r^{th}$ nearest neighbor. 

\subsection{Distributed sweep algorithm with coherence guarantee}

In this strategy we create clusters in the dense regions first, and then move to sparser regions. 

\myparagraph{Finding maximal independent sets.} At each node $p_i$, we consider the function $d_{r}(p_{i})$, and we assume, without loss of generality, that the function values $d_r(p_i)$ are distinct (ties can be broken according to node id numbers).
% at the node and at its $r$ nearest neighbors. We assume that $d_{r}$ has a unique value at every node, and break ties by node id. 
Each node $p_i$ maintains two variables:
\begin{itemize}
\item Its cluster center pointer, intialized to NULL. When node $p_i$ is assigned a cluster, its cluster center pointer is assigned. 
\item A decision state, {\em decided/undecided}, to indicate whether $p_i$ is still in contention for becoming a cluster center.
\end{itemize}
Each node $p_i$ is initially in contention to become cluster center; we prefer nodes $p_i$ with smaller values of $d_{r}(p_i)$. The algorithm operates in rounds, as follows. In each round:

\begin{enumerate}
\item Every undecided and unclustered node $p_i$ requests permission from nodes in $N_{r}(p_{i})$ to become cluster center.
\item If all nodes in $N_{r}(p_{i})$ grant permission, then $p_i$ becomes a cluster center, and all nodes in $N_{r}(p_{i})$ are marked as {\em clustered} and {\em decided}. Additionally, they all set their cluster center pointer to $p_i$. 
\item If one or more nodes in $N_{r}(p_{i})$ {\em deny} permission for $p_i$ to become cluster center, then $p_i$ marks itself as {\em decided}, implying that it will not try to become cluster center any more.
\end{enumerate}

Any node $p_j$ that receives a permission request from $p_i$ responds as follows:
\begin{enumerate}
\item  If $p_j$ is unclustered {\em and} all {\em undecided} nodes $p_{j'}\in N_{r}(p_{j})$ have values of $d_{r}(p_{j'}$ greater than $d_r(p_i)$, then node $p_j$ gives permission to $p_i$; else, 
\item if $p_j$ is already clustered, then $p_j$ {\em denies} permission to $p_i$; else, 
\item if $p_j$ is not clustered, then $p_j$ {\em defers} permission to $p_i$.
\end{enumerate}

This approach essentially performs a sweep, starting from the densest regions of the network, working towards the less dense regions. The nodes with their $r$ nearest neighbors the closest have a chance to become cluster centers, while other nodes have to wait until these clusters have been formed. Once nodes in dense regions have been clustered into tight clusters, or have decided that they cannot form an independent cluster, nodes in neighboring sparser regions get the chance to become cluster centers. 

Any node left unclustered after the above process is assigned to the cluster of the nearest center, as in step M3. 

\begin{theorem}
If node $p_i$ belongs to cluster $G$ with center $c_G$, then $|p_{i} - c_G}\leq 2 d_{r}(p_{i})$. 
\end{theorem}
\begin{proof}
If $p_i=c_G$ then the claim is trivially true. If not, then there exists a node $p_y \in N_{r}(p_i)\cap N_{r}(p_j)$ for some cluster center $p_j$. Without loss of generality, suppose $p_j$ is the first such center, that is, the one with smallest $d_{r}(p_j)$. Then, $d_{r}(p_j)\leq d_{r}(p_i)$, since otherwise $p_j$ could not have been a center before $p_i$. Thus $\abs{p_{i}-p_{j}}\leq 2 d_{r}(p_i)$ using Lemma~\ref{lem:local-lemma}. If $p_j=c_G$, then this concludes the proof. If $p_j\neq c_G$, then since in step M3 each node is assigned to the nearest center, we have $\abs{p_{i}-c_G}\leq \abs{p_{i}-c_G}\leq 2 d_{r}(p_i)$.
\end{proof}

This proof implies that the center assigned to any node is at most twice the distance to its $r^{th}$ nearest neighbor, irrespective of locations of rest of the point set. 

\subsection{Dynamic algorithm}\label{subsec:dynamic}

In this subsection, we briefly outline the adaptation of the algorithm to mobility of nodes.

\myparagraph{Mobility management.} The challenge in maintaining the clusters in face f mobility is that motion on part of any of the nodes in a cluster requires a possible update on part of the cluster. We assume that a location service such as ~\cite{abraham04LLS} is available. This system works as follows. It divides the plane into a quadtree hierarchy, where a square region is recursively subdivided into four square subregions. Each square at at each level is assigned a location server. The presence of each node is noted at the server for squares at each level containing the node. To avoid excessive updates to the hierarchy, when a node leaves a square $s$ in level $\alpha$, the servers at level $\alpha+1$ are not updated immediately. Instead, they get updated when the node has passed out of the neighborhood of $s$ consisting of $8$ other squares in level $i$. This lazy scheme guarantees a low amortized cost to keep the data up to date. 

\myparagraph{Cluster maintenance in location hierarchy.} We can adapt this scheme to our purposes as follows. Each server maintains a count of the nodes in its square. And for simplicity, we let the location servers perform the computations instead of mobile nodes and become cluster centers. Now, when a server $i$ queries for its $r$-neighborhood, this query propagates up the server hierarchy, at each level $\alpha$, checking the square $s_{\alpha}(i)$ containing $i$, and its eight neighbors, written as $N(s_{\alpha}(i))$ to see if they contain a total of $r$ mobile nodes. Suppose level $\beta$ is the first level where $N(s_{\beta}(i))$ contains $r$ nodes. The radius is this neighborhood is within a constant factor of $d_{r}(i)$. The system then returns the neighborhood $N(s_{\beta+1}(i))$ of the next higher level $\beta+1$ as the level containing at least $r$ nodes. Thus, nodes in this set plays the role of $N_{r}$ neighborhood. And the algorithms from the previous subsections apply as usual. Observe that the radius of $\beta+1$ is also $O(d_{r}(i))$. 

Next, we modify this protocol to adapt to mobility of nodes. Observe that since we take $N(s_{\beta+1}(i))$ neighborhood, a node moving from $N(s_{\beta}(i))$ to a neighboring square does not require an immediate update to $d_{r}(i)$. The update is made only when it passes out of $N(s_{\beta+1}(i))$. Thus, the number of updates caused by the mobility of a node is $O(x\log x)$ when the node has moved a distance $x$ (see~\cite{abraham04LLS}). 

The server $s_{\beta}(i)$ simply updates its nodes count on these events and does not modify cluster, until it detects that number of nodes in its neighborhood has fallen below $r$. in which case it triggers a re-clustering for all clusters with center in the neighborhood $N(s_{\beta+2}(i))$. This guarantees that cluster sizes of $r$ are preserved.

It is possible to conversely trigger re-custering when a server detects a large influx of mobile nodes. Suppose $N(s_{\beta}(i))$ is the current cluster, and  $N(s_{\alpha}(i))\subset N(s_{\beta}(i))$ detects at least $r$ nodes in its domain. Then, if $\beta-\alpha\geq 2$, it triggers a reclustering in $N(s_{\beta}(i))$.

