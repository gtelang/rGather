
*** GENERATE_CLUSTERS_AGGARWAL_BKP :ARCHIVE:
The following is a possibly buggy routine I was using, to get the results for the paper. It is also slower
because the dijhalfsfiltered should have been sorted from the get-go. Saves a lot of computations. I was also 
using R instead of bestR in the call to ~makeclusters~. It is possible I may have done this deliberately, but 
I have made the change in the above block for the sake of comparison purposes.

#+BEGIN_SRC python :noweb-ref GENERATE_CLUSTERS_AGGARWAL_BKP :exports yes 
  def generateClusters(self):
    from   colorama import Fore, Style 
    import pprint as pp 
    import networkx as nx, numpy as np, random, time 
    import scipy as sp
    import matplotlib.pyplot as plt
    import sys
    points    = self.pointCloud # a conveninent alias 
    numPoints = len( self.pointCloud )

    <<FIRST_CONDITION_PREDICATE>>
    <<MAKE_CLUSTER_CENTERS>> # There are two such assumptions. 
    <<MAKE_FLOW_NETWORK>>
    <<MAKE_AGGARWAL_CLUSTERS>>

    print "Started filtering!"

    #print "The points are ", points   
    #print "Number of points are", numPoints

    #import sys
    #sys.exit()

    dijHalfs = [0.5 * self.dist( points[ i ], points[ j ] ) 
                      for i in range( numPoints ) 
                      for j in range( i+1, numPoints ) ]
    # Find all dijs satisfying condition 1 on page 4

    print "dijhalfs computed", len(dijHalfs)
    dijHalfsFiltered =  filter( firstConditionPredicate, dijHalfs )  #smallest to highest
    print "dijHalfsFiltered done!"

    # 'FOR' Loop to find the minimum 'R' from these filtered dijs satisfying 
    #  condition 2 on page 4 of the paper. 
    bestR, bestRflowNetwork, bestRflowDict = float( 'inf' ), nx.DiGraph(), {} 
    bestRCenters = []

    from termcolor import colored

    for R in dijHalfsFiltered : # The first R that goes through the else block is the required R
     
      print colored(str(R) + 'is being tested', 'red', 'on_white', ['underline', 'bold'])
      clusterCenters = makeClusterCenters( R )
      flowNetwork    = makeFlowNetwork( R, clusterCenters )

      try: # Check if a feasible flow exists in the constructed network.  
            flowDict = nx.min_cost_flow( flowNetwork )

      except nx.NetworkXUnfeasible:# If not, try the next R
            print Fore.RED, "Unfeasible R detected: R= ", R, Style.RESET_ALL
            continue 
      else: # Found a feasible R.  
          print "Found a feasible R! R= ", R
          if R < bestR: # Yippee a smaller and feasible R! Update bestR. 
              print Fore.RED, " In fact, it is the best thus far ", Style.RESET_ALL 
              bestR            = R
              bestRflowNetwork = flowNetwork
              bestRflowDict    = flowDict
              bestRCenters     = clusterCenters


    #Use the best network to construct the needed clusters. 
    self.computedClusterings = makeClusters( bestRflowDict, bestRCenters, bestRflowNetwork, R)

    # Sanity check on the computed clusters. They should all be of size r and should cover the full point set
    assert( all( [ len(cluster) >= self.r for cluster in self.computedClusterings ] ) )
    assert( len( { i for cluster in self.computedClusterings for i in cluster } ) == numPoints   )
    print Fore.YELLOW, "Yay All points Covered!!", Style.RESET_ALL
   
    print "BestRCenters are ", bestRCenters 
    return  bestRCenters
#+END_SRC


#+BEGIN_SRC python :noweb-ref FIRST_CONDITION_PREDICATE :exports none 
  def firstConditionPredicate( R ):
      import time

      # # Team Scipy
      # start = time.time()
      # #print R
      # distances, everyonesBall2R_Neighbors = self.rangeSearch( self.pointCloud, 2*R )
      # end = time.time()
      # print(end - start), "seconds"
      #assert( len( everyonesBall2R_Neighbors ) == len( self.pointCloud ) )
      # Check if everyone has sufficiently many neighbours.
      #return  all(   [True if len(nbrList) >= self.r else False 
      #                     for nbrList in everyonesBall2R_Neighbors]   )

      start = time.time()
      distances, r_nearest_indices = self.findNearestNeighbours( self.pointCloud, self.r  ) # This is the bottleneck inside your code.      
      endknn = time.time()
      print 'Just the knn inside firstConditionPredicatetook ', (endknn-start), "seconds"

      #------------------ Gold
      #flags = []
      #for i in range( numPoints ):
      #    flagi = [True if self.dist( self.pointCloud[i], self.pointCloud[nbr]  ) <= 2*R  else False for nbr in r_nearest_indices[i] ] 
      #    flags.append( all(flagi) )
       
      #    #if all( flagi ): # All points within the distance of 2*R
      #    #    flags.append( all(flagi)  )

      #return all( flags ) 

      #------------------ Bench
      for i in range( numPoints ):
          for j in range(len(r_nearest_indices[i])):
               if distances[i][j] >= 2*R :
                    endfn   = time.time()
                    print 'firstConditionPredicate took ' , (endfn-start) , "seconds"
                    return False

      endfn   = time.time()
      print 'firstConditionPredicate took ' , (endfn-start) , "seconds"
      return True # non of flagis tested negative.


#+END_SRC 

The noweb-reference makeClusterCenters expands to the function definition given below. Neighbours of a point within
the distance $2R$ are chosen naively simply by iterating over the point cloud. I don't know how to do subquadratic 
time neighbour searches in general metric spaces. 

/*NOTE* :: It is not immediately clear why the ~while~ loop below *must* terminate. Aggarwal et al.  do not prove this statement.  Possible 
 issue to be raised with Prof. Gao and Rik? But I suppose it might work for low values....$r = 2,3$...Not sure.Will need to check this out properly./
/Possible hacks: if the loop looks like it is infinite, terminate it, and figure out how to treat these points./
#+BEGIN_SRC python :noweb-ref MAKE_CLUSTER_CENTERS :exports no
  def makeClusterCenters( R,
                          points = self.pointCloud, 
                          dist   = self.dist      , 
                          r      = self.r         ):
        """ Marking loop for choosing good cluster centers """
        import numpy as np
        from sklearn.neighbors import NearestNeighbors

        numPoints               = len( points )
        markers                 = [ False for i in range( numPoints ) ]
        potentialClusterCenters = [ ] # Populated in the while loop below.  
   
        # Warning: The n_neighbors=r was chosen by me arbitrarily. Without this, the default parameter chosen by sklearn is 5
        # Might have to do replace this with something else in the future me thinks.  
        #nbrs_datastructure = NearestNeighbors (n_neighbors=r, radius=2*R , algorithm='ball_tree',metric=self.dist , n_jobs=-1).fit( points ) 
        # See note above. It might be very important! 
        # The following while loop replacement to the confusing tangle spelled out in the Aggarwal 
        # paper was suggested by Jie and Jiemin in the email thread with Rik, after I cried for help. 

        # First get all the points within distance 2*R for EVERY point in the cloud.
        (_, idx_nbrs_2R) = self.rangeSearch( points, 2.0*R )
        while( all( markers ) !=  True ): 
             
            unmarkedIndices =  [ index for ( index,boolean ) 
                                       in zip( range( numPoints ), markers) 
                                       if boolean == False ]
         
            randomIndex          = random.choice ( unmarkedIndices ) 
            ball2R_neighbor_list = idx_nbrs_2R[randomIndex]
            #print ball2R_neighbor_list 
 
            # Mark all the neighbours including the point itself. 
            for nbrIndex in ball2R_neighbor_list:
                   markers[ nbrIndex ] = True 
    
            potentialClusterCenters.append( ( randomIndex, ball2R_neighbor_list ) ) 


        print " All points marked! "
        # Cluster centers are those which have atleast r points in their neighbourhood. 
        clusterCenters = [ index for ( index, ball2R_neighbor_list ) in potentialClusterCenters 
                            if len( ball2R_neighbor_list ) >= r  ]


        # Having marked all the points, return the cluster centers. 
        return clusterCenters
#+END_SRC



#+BEGIN_SRC python :noweb-ref MAKE_CLUSTER_CENTERS_JUL29_WORKING_FOR_R2L2_BUT_BUGGY :exports no
  def makeClusterCenters( R,
                          points = self.pointCloud, 
                          dist   = self.dist      , 
                          r      = self.r         ):
        """ Marking loop for choosing good cluster centers """

        from scipy import spatial

        numPoints               = len( points )
        markers                 = [ False for i in range( numPoints ) ]
        potentialClusterCenters = [ ] # Populated in the while loop below.  
    
        # For fast neighbour search in the while loop below. 
        mykdtree = spatial.KDTree( self.pointCloud )
        
        # See note above. It might be very important! 
        # The following while loop replacement to the confusing tangle spelled out in the Aggarwal 
        # paper was suggested by Jie and Jiemin in the email thread with Rik, after I cried for help. 
        while( all( markers ) !=  True ): 
             
            unmarkedIndices =  [ index for ( index,boolean ) 
                                       in zip( range( numPoints ), markers) 
                                       if boolean == False ]
         
            randomIndex = random.choice ( unmarkedIndices ) 

            # WARNING: THE INDICES ARE NOT SORTED ACCORDING TO THE DISTANCE FROM the RANDOMINDEX point
            ball2R_neighbor_list = mykdtree.query_ball_point( points[randomIndex] , 2*R)
            
            #ball2R_neighbor_list = [ index for index in range( numPoints ) 
            #                               if dist( points[ randomIndex ], points[ index ]) <= 2*R ] 

            # Mark all the neighbours including the point itself. 
            for nbrIndex in ball2R_neighbor_list:
                   markers[ nbrIndex ] = True 
    
            potentialClusterCenters.append( ( randomIndex, ball2R_neighbor_list ) ) 


        print " All points marked! "
        # Cluster centers are those which have atleast r points in their neighbourhood. 
        clusterCenters = [ index for ( index, ball2R_neighbor_list ) in potentialClusterCenters 
                            if len( ball2R_neighbor_list ) >= r  ]


        # Having marked all the points, return the cluster centers. 
        return clusterCenters
#+END_SRC


#+BEGIN_SRC python :noweb-ref MAKE_CLUSTER_CENTERS_MY_ASSUMPTION :exports none 
  def makeClusterCenters( R,
                          points = self.pointCloud, 
                          dist   = self.dist      , 
                          r      = self.r         ):
      """ Marking loop for choosing good cluster centers """
      
      numPoints      = len( points )
      markers        = [ False for i in range( numPoints ) ]
      clusterCenters = [ ] # Populated in the while loop below.  
   
      # See note above. It might be very important! 
      while( all( markers ) !=  True ): 
           
          unmarkedIndices =  [ index for ( index,boolean ) 
                                 in zip( range( numPoints ), markers) 
                                 if boolean == False ]
       
          randomIndex = random.choice ( unmarkedIndices ) 

          ball2R_unmarked_neighbors_list = [ index  for index 
                                              in range( numPoints ) 
                                              if dist( points[ randomIndex ], points[ index ]) <= 2*R 
                                              and index in unmarkedIndices] 

          if ( len( ball2R_unmarked_neighbors_list ) >= r ): # The random point chosen requires atleast r unmarked neighbours for being a cluster center. 

               # Cluster centers are guaranteed to have r points in the 2*R ball
               clusterCenters.append( randomIndex ) 
               # Mark all the neighbours including the point itself. 
               for nbrIndex in ball2R_unmarked_neighbors_list:
                   markers[ nbrIndex ] = True 
          else: # Just mark the point but not the neighbours. This is one hack around the infinite loop. Second would be to detect the infinite loop and add it to the cluster center list.
               markers[ randomIndex ] = True # Even though we mark it here, WE DON'T INCLUDE it as a cluster center. 
   
      print "Yay! While Loop Cleared!  \n\n"
      # Having marked all the points, return the cluster centers. 
      return clusterCenters
#+END_SRC
#+BEGIN_SRC python :noweb-ref MAKE_FLOW_NETWORK :exports none 
  def makeFlowNetwork( R                       ,
                       clusterCenters          ,
                       points = self.pointCloud,
                       r      = self.r         ): 

      # Set the nodes of the network and some attributes
      numPoints = len( points )
      G = nx.DiGraph() # Initialize an empty flow network

      G.add_node( 's', demand = -r*len(clusterCenters) ) # Source
      G.add_node( 't', demand =  r*len(clusterCenters) ) # Sink
      G.add_nodes_from( range(numPoints) ) # The actual points 


      # Give cluster centers a special attribute marking it as a center. 
      isClusterCenterDict = { } 

      for i in range( numPoints ):
          if i in clusterCenters:
              isClusterCenterDict[ i ] = True
          else:
              isClusterCenterDict[ i ] = False

      # Source and sink are "fake" nodes and hence not centers.
      isClusterCenterDict['s'] = False
      isClusterCenterDict['t'] = False

      nx.set_node_attributes( G,'isCenter', isClusterCenterDict )

      # Set the EDGES of the network and its sttributes
      # Source edges
      for i in clusterCenters:
          G.add_edge( 's', i , capacity = r )

       # Interior edges i.e those whose endpoints are neither 's' not 't'
       #distances, nbrlistsClusterCenters = self.rangeSearch( [ points[ i ] for i in clusterCenters ] , 2*R   ) # For each cluster center, get neighbours in the point-cloud within distance 2*R.

       #      print clusterCenters, R
       #      print nbrlistsClusterCenters
       #      import sys
       #      sys.exit() 

       #      for i in clusterCenters:
       #          for j in nbrlistsClusterCenters : # For each of i's neighbours, except itself, add an edge in the flow network emanating from i's node
       #              if i != j:
       #                G.add_edge (i, j, capacity = 1.0)  
              

      for i in clusterCenters:
           for j in range( numPoints ):

               if i != j and self.dist( points[ i ], points[ j ] ) <= 2*R:
                  G.add_edge( i, j, capacity = 1.0 ) 



      # Sink edges
      for i in range( numPoints ):
          G.add_edge( i, 't', capacity =  1.0 )

      return G
#+END_SRC



#+BEGIN_SRC python :noweb-ref MAKE_AGGARWAL_CLUSTERS :exports none 
  def makeClusters( bestRflowDict, clusterCenters, bestRflowNetwork , R ):
      """ Construct the clusters out of the network obtained.  """ 

      pp.pprint ( bestRflowDict )
      clusterings = [ ] 
      for v in bestRflowNetwork.nodes():
          
          if bestRflowNetwork.node[ v ]['isCenter'] == True: 
            # Every cluster center becomes 
            # the first node of its cluster. 
            cluster = [ v ]

            for successor in bestRflowNetwork.successors( v ): 

              if successor != 't':
                 #print "v= ", v, " successor= ", successor
                 if bestRflowDict[ v ][ successor ] > 1-0.001: # Have to be careful.since comparing to 1.0 may be problematic. Hence the little cushion of 0.001
                     cluster.append( successor )

            assert( len( cluster ) >= self.r  )
            # Wrap up by registering this newly reported cluster.
            clusterings.append( cluster )

      # Some nodes (FORGET ABOUT 'S' AND 'T', THEY DON' COUNT ANY MORE) were probably missed 
      # by the clusters. Add them to one of the clusters obtained above. 
      coveredNodes = set([ i for cluster in clusterings for i in cluster ] )
      missedNodes  = set(range( numPoints ) ).difference( coveredNodes )

      #print missedNodes

      for missedNode in missedNodes:
         
          # Find the cluster whose center is nearest to missedNode
          dist2NearestClusterCenter = float("inf")
          for i in range( len( clusterings ) ):
              clusterCenter      = clusterings[i][0]# Head of the cluster is the center. 
              dist2clusterCenter = self.dist( points[ missedNode ] , points[ clusterCenter ] ) 
              if dist2clusterCenter <= min( dist2NearestClusterCenter, 2*R):
                  dist2NearestClusterCenter = dist2clusterCenter
                  nearestClusterIndex       = i # WARNING! This does NOT index into points. It indexes into clusterings array

          clusterings[ nearestClusterIndex ].append( missedNode )        


      # Add missed nodes to clusters  
      # for missedNode in missedNodes:
      #     for cluster in clusterings:
      #         clusterCenter      = cluster[ 0 ] # That's how the clusters were constructed in the for loop
      #         dist2clusterCenter = self.dist( points[ missedNode ], points[ clusterCenter ]) 
      #         if dist2clusterCenter <= 2*R: # TODO
      #             print Fore.CYAN, dist2clusterCenter, " <= ", 2*R, Style.RESET_ALL 
      #             print "Appending missed node ", missedNode, " to cluster with Center ", clusterCenter 
      #             cluster.append( missedNode )
           

      #print Fore.YELLOW, clusterings, Style.RESET_ALL

      # Make sure all points have been covered in the clustering
      return clusterings
#+END_SRC

* Scrap notes :ARCHIVE:
:PROPERTIES:
:tangle: no
:mkdirp: no
:END:
 - Selecting an arbitrary submatrix of numpy. 

#+BEGIN_SRC python
In [18]: matrix
Out[18]: 
array([[ 0,  1,  2,  3,  4,  5],
       [ 6,  7,  8,  9, 10, 11],
       [12, 13, 14, 15, 16, 17],
       [18, 19, 20, 21, 22, 23],
       [24, 25, 26, 27, 28, 29],
       [30, 31, 32, 33, 34, 35]])
In [19]: matrixslice = matrix[ np.ix_ (  [0,4,5] , [0,2,5]   )   ] # A convenience function provided by numpy

In [20]: 

In [20]: 

In [20]: matrixslice
Out[20]: 
array([[ 0,  2,  5],
       [24, 26, 29],
       [30, 32, 35]])
#+END_SRC

** Animation in Python
For pulleys I did not use the animation module. Here we do since we need to understand the decision the algorithm
makes as the cars move along the trajectories.m 


*** animation.FuncAnimation (...)
Generate the ith frame of an animation sequence. Thus you could say, its signature is ~Int -> IO Frame~ where 
Frame is the final picture returned.  

#+BEGIN_SRC python :results output
"""
A simple example of an animated plot
"""
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation

fig, ax = plt.subplots()

x = np.arange(0, 2*np.pi, 0.01)
line, = ax.plot(x, np.sin(x))


def animate(i):
    line.set_ydata(np.sin(x + i/10.0))  # update the data
    return line,


# Init only required for blitting to give a clean slate.
def init():
    #line.set_ydata(np.ma.array(x, mask=True))
    return line,

ani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init,
                              interval=25, blit=True)
plt.show()

#+END_SRC


MAtplotlib can save video as an html5 video!! Basically all you need to do is provide an .mp4 or .ogg video
in the h264 encoding HTML5 format. It spits out a long hexadecimal like string.  
Then every browser (major ones atleast) will be able to play that video 
with their own media player which comes inbult. This means you don't need to distribute copies of vlc to other
people, neither upload that video to youtube and then emebed it. Yay!! 
See this video to customize the embedding: https://www.youtube.com/watch?v=9pN7UT5S64I


Essentially you surround the video link in the video tag, with some extra attributes. See here for a classic example! 
See the browser support table in the middle of this page: http://www.w3schools.com/html/html5_video.asp 
Plays on iPhone/iPad devices too!

See this for more on MATPLOTLIB html5 embedding: http://yt-project.org/doc/cookbook/embedded_webm_animation.html

*** Data structures
Each trajectory shuld be a class. 
There should a distance function between two trajectories accepting them

* Types and Typeclasses :ARCHIVE:

I'll use Haskell syntax to succinctly specify the dramatis personae of this program. I'll then use  
abstract base classes and inheritance  to emulate their relationships in Python. 


- Typeclasses :: 
  - *~MetricSpace~*: A minimum complete definition will contain
    - *A Distance function* satisfying properties of a metric.
      [fn:prop-check: You should provide a property-checker for the metric using [[https://hypothesis.readthedocs.io/en/latest/][Hypothesis]]. 
      [[http://developers.redhat.com/blog/tag/python/#post-424075][Here]] is a fantastic 30 minute overview of various features of this library. It is heavily 
      inspired by Haskell's Quickcheck  ]
     
     
- Types ::
   - *~data Point = Point Double Double~*  
       - This type models points in $\mathbb{R}^2$ with the Euclidean metric. 
       - *_Instances_*
         -  MetricSpace

   - *~data Trajectory = Trajectory [ Point ]~*
       - This type models piece-wise linear trajectories in $\mathbb{R}^2$. 
       - *_Instances_*
         -  MetricSpace  [fn:jiemin-metric: For trajectories $T_1$, and $T_2$, the function $d(T1,T2) = \max_{p \in T_1, q \in T_2} d(p,q)$ is a metric] 

* Scrap :ARCHIVE:
   # # Select cluster centers in a greedy manner. Just mark all neighbours. 
      # # Don't care if the neighbours are marked or unmarked as described in the 
      # # paper. Requires clusterCenters to be a dictionary. 
      # while( all(markers) != True ):  # unmarked means uncovered
         
      #     # Indices of uncovered points 
      #     unmarkedIndices =  [ index for ( index,boolean ) 
      #                           in zip( range( numPoints ), markers) 
      #                           if boolean == False ]
       
      #     # Choose a random point not already chosen to be a cluster center
      #     choice_list = [ index for index in range( numPoints ) if index not in clusterCenters.keys()]
      #     randomIndex = random.choice ( choice_list ) 
   
      #     # Get all neighbours within distance 2R
      #     ball2R_list = [ index  for index 
      #                            in range( numPoints ) 
      #                            if dist( points[ randomIndex ], points[ index ]  )  <= 2*R ]

      #     # Assertion should not fail, since we have cleared condition 1. 
      #     assert ( len( ball2R_list ) >= r ) # Seems to be working under my new hypothesis 
             
      #     clusterCenters[ randomIndex ] = ball2R_list

      #     # Mark the points covered. 
      #     for nbrIndex in ball2R_list:
      #          markers[ nbrIndex ] = True 
     
      # print "Yay! While Loop Cleared!  \n\n"

      # # Having marked all the points, return the cluster centers. 
      # return clusterCenters

* Things to do for the dynamic rGather program :ARCHIVE:
- [X] Make a main file from the animation file
- [X] Go through the visualization routine. Adapt it to the visualization 
      for this case. 
- [X] Add another class which derives from the metric space class
- [ ] Implement the 0 regroupings allowed. k passed as a parameter. 
- [ ] Visualize the trajectories statically. Trajectories in a cluster are colored with the same color.
- [ ] Use the Delaunay triangulation heuristic for the r=3 case
  - [ ] Learn how to use delauny triangulation. Scipy has a routine
  - [ ] I know how to use Linear Programming already. Just replace it with 
        a linear program. USeful to understand the LP relaxation of it though. 
        But if needed you can directly use your LP setcover heuristic that 
        you implemented in here. 
- [ ] Implement the epsilon kernel routine. 
  - [ ] It would be extremely useful to make a gridding function. 
        You had implemented a similar one, in C++ some time back. 
        Basically I think you would perform bucketing. *Add this to pointLib.py*
        the library you wrote which handles interactive stuff, and can be appended 
        to algorithms. 
  - [ ] This is a very simple algorithm. The only complex 
        part is setting the parmaters
  - [ ] The epsilon kernel routine is implemented as part of 
        a new aproximate rGather algorithm with the same 
        structure as wht you did before. The only twist, 
        would be that you generate the clusters, by passing an 
        additional parameter, which is the approximation parameter 
        called epsilon. 
  - [ ] Have statistics to record the statistics of the sizes of the 
        coresets, and other such trivia. 
- [ ] Get properties of the proposed rGather coreset algorithm 
     which uses onion layers.
- [ ] This can be easily implemented in an interactive frame 
      by adapting the routine AlgoJieminDecentralizedStatic.
- [ ] The recursive improvement step, I think will be crucial to 
      get improved results. Don't neglect the importance of this step. 
