#+TITLE: r-Gather Programs
#+PROPERTY: tangle  no
#+PROPERTY: exports none 
#+INFOJS_OPT: path:/home/gaurish/Dropbox/MyWiki/codes/Haskell/LiterateHaskell/org-info.js view:info toc:nil   
* Introduction

The $r$-Gather problem was originally posed as a sub-problem in a [[http://people.csail.mit.edu/karger/Papers/maybecast.pdf][FOCS 2000]] paper about constructing Steiner trees in 
the face of uncertainty. It was explored in detail by [[http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41225.pdf][Aggarwal et al. ]]who gave various hardness results and 
approximation algorithms in the setting of metric spaces. It is natural to study this problem and its variants 
in $\mathbb{R}^2$ by exploiting the extra structure available. 

In the main paper, we give approximation algorithms for the following problems:

*DYNAMIC $r$-GATHER:* If the $(x,y)$ co-ordinates of the data-set are live and moving, how do we update $OPT$ efficiently? 
 
*DECENTRALIZED $r$-GATHER:* Say the data-set is spread among several data-banks. How do we compute $OPT$ 
with minimal co-ordination? 
  
*DECENTRALIZED DYNAMIC $r$-GATHER:*  What if the data is live, _/*and*/_ the computation 
is required to be as decentralized as possible?  

The sections that follow give literate Python implementations of these algorithms [fn:python-info: I'll be using the latest Anaconda installation of Python 2.7. Note that some older versions of Matplotlib give errors 
when trying to do the animation with generators as documented [[https://github.com/matplotlib/matplotlib/pull/2634][here]]. However, the version of Matplotlib bundled up in Anaconda's latest Python 2.7+ environment does not have these problems] 

* About the Test Data
#+attr_html: :width 550px
#+attr_html: :align left 
[[file:./shenzhen_trajectory_data.png][file:./InputOutput/shenzhen_trajectory_data.png]]
Figure 1 on the left depicts trajectories of 9386 cars, fitted with GPS sensors, driving 
around Shenzhen, China for a single day. [[file:shenzen_normalized_data_animation_for_small_subset_of_cars.mp4][Here]] is a video of a small subset of them evolving in time.  

The GPS co-ordinates from the raw data set (consisting of latitude and longitude given in degrees) 
have been "normalized"; so we can assume the cars have been sampled in lock-step, every 5 minutes.
 
The goal of the $r$-Gather problem and its variants is -- broadly speaking -- to fuzz these trajectories for anonymity, 
yet still preserve enough structure to make useful inferences. 



* The Implementations 
I will be implementing each of the five algorithms as classes in *~rGather.py~*. These classes will behave as 
namespaces for different runs of the algorithms. *There will be no dependence between the classes*. That will 
allow us to unit-test them individually.  

Each class comes with its own @@html:<font color = "red">@@ main.py @@html:</font>@@  
file to customizing the needed logic. But the module file remains the same. I will not be documenting the 
logic of the *main.py* files in this literate document, for they are self-explanatory. 

The statistics of the clustering, on the other hand will be visualized by the *plotStatistics* method 
It will get its own axes artist object(s) on which to plot these statistics. 

I intend to use the classes as described below:

- _Test the performance of various algorithms on a stored data-set_ :: 
  - Initialize *(but not necessarily start!)* one or more $r$-Gather routines with the input-data.
  - Every class has a method called *~generateState({config})~* which runs the actual
    algorithm on the provided input. The computed clusterings and statistics of the 
    run are stored as member variables or maybe as a dictionary. 
  - Each class also has one or more functions for visualizing the clusterings or 
    run-time statistics so gathered. 
  - The dynamic algorithms also come with one or more animation functions  
    interacting with the *~generateState()~* via the *~yield~* statement and the 
    *~animation.FuncAnimation(..)~* HOF.  
  - Every method itself will have routines local to its scope to help abstracting away its logic. 
    Strive to make these local routines pure. Moreover, make all the needed module imports local.  
    That will help us via property checkers or other unit-testing mechanisms. 


- _Stress test an algorithm adversarially via the little GUI_ ::
   - The user enters the points by double-clicking on the canvas. 
     
   - To set the $r$-parameter he will 
     - Press *r* or *R* key
     - Then enter the decimal digits of this parameter. 
     - After finishing, press enter, to execute the algorithm.
  
   - To clear the canvas and reset the algorithm class which is 
     holding the state press *c* or *C* key. 

   - Start inputting a new cloud of points to have a new run of the 
     algorithm. 

-----

Finally, every run will need to record the statistics inside a YAML or an XML file. 
XML might be simpler if you will be using Beautiful soup. Besides the documents 
are far easier to view in the browser. YAML cannot be folded up unfortunately.
I will absolutely need the latter for viewing small-data-sets. 

There must be a function which produces this output! The following list should 
be produced for each point-cloud data-set. Note that the results from different 
clustering algorithms will be stored in the same file.   

- _Static RGather_ ::
  - Comment String. Allowed to be arbitrarily long. 
  - The number of points 
  - (x,y) coods of the points
  - List of clusterings computed different algorithms. 
    $\forall$ clustering
       - Algorithm Used
       - $r$ parameter
       - Number of clusters computed. 
       - Now the actual clusters! 
         $\forall$ clusters
         - The number of points in the cluster
         - The diameter of the cluster
         - The actual points of the cluster. 

We could stuff everything ever into one 
data-file but that would be too complicated! 

